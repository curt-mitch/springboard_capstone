{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook fetches several translation examples from Google's translation API and rates those translations using the METEOR score metric.\n",
    "\n",
    "#### METEOR (Metric for Evaluation of Translation with Explicit ORdering) is an algorithm used to score and evaluate the accuracy of a machine translation by comparing how close it is to a human-derived translation. Unlike the more common BLEU score, it is intended to be used on individual sentences rather than an entire corpus. See https://en.wikipedia.org/wiki/METEOR for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import six\n",
    "import json\n",
    "from google.cloud import translate_v2 as translate\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/curtismitchell/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get JSON file of sentence pairs\n",
    "benchmark_directory = os.getcwd()\n",
    "os.chdir(os.path.join(benchmark_directory, './..'))\n",
    "sentences_file = open('./subtitle_corpus.json', 'r')\n",
    "sentences_json = json.load(sentences_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(benchmark_directory, './..'))\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = './credentials/Google-Cloud-a8fd3d0a789d.json'\n",
    "ACCESS_CODE = os.getenv(\"accessCode\")\n",
    "translate_client = translate.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab 100 random sentence pairs\n",
    "num_sentences = len(sentences_json) - 1\n",
    "random.seed(42)\n",
    "selected_sentence_pairs = []\n",
    "for _ in range(100):\n",
    "  i = random.randrange(0, num_sentences)\n",
    "  selected_sentence_pairs.append(sentences_json[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for retrieving individual translations via Google Translation API\n",
    "def retrieve_google_translation(text):\n",
    "  if isinstance(text, six.binary_type):\n",
    "      text = text.decode('utf-8')\n",
    "\n",
    "  # Text can also be a sequence of strings, in which case this method\n",
    "  # will return a sequence of results for each text.\n",
    "  result = translate_client.translate(\n",
    "      text,\n",
    "      source_language = 'ja',\n",
    "      target_language='en')\n",
    "\n",
    "  # print(u'Text: {}'.format(result['input']))\n",
    "  # print(u'Translation: {}'.format(result['translatedText']))\n",
    "  return result['translatedText']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_translations = []\n",
    "\n",
    "for sentence_pair in selected_sentence_pairs:\n",
    "  ja_text = sentence_pair['j']\n",
    "  sentence_pair['gc_result'] = retrieve_google_translation(ja_text)\n",
    "  benchmark_translations.append(sentence_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank Spacy tokenizer with just the English vocab\n",
    "nlp = English()\n",
    "tokenizer = nlp.Defaults.create_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n"
     ]
    }
   ],
   "source": [
    "# Count number of unique words in sample sentences as we want at least 1000 unique words\n",
    "word_list = []\n",
    "for translation in benchmark_translations:\n",
    "    word_list += [token.text for token in tokenizer(translation['e'])]\n",
    "\n",
    "print(len(set(word_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate METEOR for each sentence\n",
    "meteor_scores = []\n",
    "for translation in benchmark_translations:\n",
    "    score = single_meteor_score(translation['e'], translation['gc_result'])\n",
    "    meteor_scores.append(round(score, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 0.755\n",
      "min: 0.0\n",
      "mean: 0.224539\n",
      "stdev: 0.21867785443247773\n",
      "median: 0.16\n"
     ]
    }
   ],
   "source": [
    "# Descriptive stats for meteor scores\n",
    "from statistics import mean, stdev, median\n",
    "\n",
    "print(\"max: \" + str(max(meteor_scores)))\n",
    "print(\"min: \" + str(min(meteor_scores)))\n",
    "print(\"mean: \" + str(mean(meteor_scores)))\n",
    "print(\"stdev: \" + str(stdev(meteor_scores)))\n",
    "print(\"median: \" + str(median(meteor_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Older scores from Kyoto Corpus:\n",
    "max: 0.9375\n",
    "\n",
    "min: 0.0\n",
    "\n",
    "mean: 0.316994\n",
    "\n",
    "stdev: 0.21899833301335025\n",
    "\n",
    "median: 0.2957"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
